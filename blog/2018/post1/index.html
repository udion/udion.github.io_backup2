<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Uddeshya Upadhyay | Uncertainty in DNNs</title>
<meta name="description" content="Homepage for Uddeshya Upadhyay. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/css/mdb.min.css" integrity="sha256-/SwJ2GDcEt5382i8zqDwl36VJGECxEoIcBIuoLmLR4g=" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"  integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2018/post1/">

<!-- Open Graph -->


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
    
  </head>

  <d-front-matter>
    <script type="text/json">{
      "title": "Uncertainty in DNNs",
      "description": "",
      "published": "2018-09-05 00:00:00 +0530",
      "authors": [
        
        {
          "author": "Uddeshya Upadhyay",
          "authorURL": "https://udion.github.io/",
          "affiliations": [
            {
              "name": "IIT-Bombay",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
        
        <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/"><span class="font-weight-bold">Uddeshya</span> Upadhyay</a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              Blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/_pages/cv/">
                CV
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Uncertainty in DNNs</h1>
        <p></p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <p>This is an attempt to understand and recreate the work presented in <a href="https://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision.pdf">What Uncertainties Do We Need in Bayesian Deep
Learning for Computer Vision?</a> by alex kendall and yarin gal.</p>

<p>The paper proposes framework to include uncertainty in context of classification as well as regression by deep neural network.
For the purpose of this article I will stick to uncertainty in context of some regression by deep neural nets.</p>

<p>Broadly uncertainty can be of two types</p>

<p><code class="language-plaintext highlighter-rouge">Aleatoric</code> : uncertainty inherently in the observation (i.e sensor which captured the data was malfunctioning, obtaining more data from such a sensor won’t help cure the problem)</p>

<p><code class="language-plaintext highlighter-rouge">Epistemic</code> : uncertainty in the model parameters, this can be explained away with more data</p>

<p>Author proposes a method to account for both type of uncertainties in a given baseline model (baseline model doesn’t acount for uncertainty).</p>

<p>Suppose the baseline model has the loss function:
<script type="math/tex">% <![CDATA[
\begin{eqnarray} 
L_{base} &=& \frac{1}{D}\sum_i\frac{1}{2}||y_i - \hat{y_i}||^2
\end{eqnarray} %]]></script>
Here $D =$ number of pixels in the output and $\hat{y_i}$, $y_i$ are predicted pixel value and ground truth pixel value for pixel $i$, where sum is over all the pixels.</p>

<p>To account for uncertainties, we should</p>

<ul>
  <li>Introduce dropouts</li>
  <li>Tweak the model such that instead of outputing a value say $\mathbf{\hat{y}}$, it will output a tuple $(\mathbf{\hat{y}}, \mathbf{\hat{\sigma^2}})$ where $\mathbf{\hat{\sigma^2}}$ will represent the uncertainty in $\mathbf{\hat{y}}$</li>
  <li>changing the loss function to
<script type="math/tex">% <![CDATA[
\begin{eqnarray} 
L_{BNN} &=& \frac{1}{D}\sum_i{\frac{1}{2\hat{\sigma_i^2}}||y_i - \hat{y_i}||^2+\frac{1}{2}\log\hat{\sigma_i^2}}
\end{eqnarray} %]]></script></li>
  <li>Introduce weight decay</li>
</ul>

<p>this will try to learn the uncertainty without any supervision, $\log\hat{\sigma_i^2}$ will prevent the uncertainty from blowing up,
where as $\frac{1}{2\hat{\sigma_i^2}}$ will prevent uncertainty to going down to zero.
This is like base loss function except that it is weighted using uncertainty and the hope is that we will hit a sweet spot
where network is still outputing values close to original ground truth but also giving us idea about uncertainty (which is non-zero and not infiinity)</p>

<p>for training it’s better to use $s_i = \log\sigma_i^2$ as this will prevent a possible division by zero operation.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{eqnarray}
L_{BNN} &=& \frac{1}{D}\sum_i{\frac{1}{2}\exp(-s_i)||y_i - \hat{y_i}||^2 + \frac{1}{2}s_i}
\end{eqnarray} %]]></script>

<h2 id="experiment">Experiment</h2>
<p>In order to see it in action, consider the toy problem where I have created an autoencoder for MNIST, 
then I have modified this autoencoder by introducing</p>

<ul>
  <li><strong>dropout layers</strong> after every convolution layer</li>
  <li>splitting the last layer of the network <strong>into 2 parts, one for $\mathbf{\hat{y}}$ and other for $\mathbf{\hat{\sigma^2}}$</strong></li>
</ul>

<p>The modified network is train with the above mentioned $L_{BNN}$ with $L2$ norm penalty on the weights of the model. The following diagram shows
the oriignal network and modified network
<img src="../../../assets/img/mnistuae.png" alt="drawing" width="750" /></p>

<h2 id="expectation">Expectation</h2>
<p>My expectation is that even with modified autoencoder (with uncertainty) I should be able to get good reconstruction of digits and uncertainty maps should be something that makes sense visibily. 
<strong><em>I’m not sure if this is achievable</em></strong></p>

<h2 id="results">Results</h2>
<ul>
  <li>With plain auto-encoder after 20 epochs:
  <img src="../../../assets/img/ae1.png" alt="drawing" width="750" /></li>
  <li>With modified auto-encoder after 20 epochs, here the <code class="language-plaintext highlighter-rouge">log variance map</code> corresponds to $s$ (i.e $\log\hat{\sigma^2}$) values which was used in loss function
and <code class="language-plaintext highlighter-rouge">variance map</code> corresponds to $\log\hat{\sigma^2}$ values
<img src="../../../assets/img/uae1.png" alt="drawing" width="750" /></li>
</ul>

<h2 id="thoughts">Thoughts</h2>
<ul>
  <li>Uncertainty is usually high only among the pixels which are in the neighborhood of the pixels which represent non-zero ground truth values. 
The black background usually does not have high uncertainty, this looks ok</li>
  <li>The contributions from uncertainty is too high and distrubs the gradients as a result reconstruction is not good.</li>
</ul>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Uddeshya Upadhyay.
    
    
    Last updated: July 17, 2020.
    
  </div>
</footer>



  </body>

  <!-- Load Core and Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.0/umd/popper.min.js" integrity="sha256-OH05DFHUWzr725HmuHo3pnuvUUn+TJuj8/Qz9xytFEw=" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.17.0/js/mdb.min.js"  integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load KaTeX -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" integrity="sha256-V8SV2MO1FUb63Bwht5Wx9x6PVHNa02gv8BgH/uH3ung=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js" integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc=" crossorigin="anonymous"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Mansory & imagesLoaded -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>







  <d-bibliography src="/assets/bibliography/">
  </d-bibliography>

</html>
